# Лабораторна робота №2 
# з дисципліни "Машинне навчання"
# студента групи ШІ Ходакова Максима Олеговича

### Dataset: https://www.kaggle.com/datasets/uciml/iris  

####
ЛОГІСТИЧНА РЕГРЕСІЯ ДЛЯ КЛАСИФІКАЦІЇ IRIS (L2 vs L1) З ПОВНИМИ ПОЯСНЕННЯМИ
-----------------------------------------------------------------------------

Що робить скрипт:
1) Завантажує датасет Iris з CSV (колонки: Id, чотири ознаки, Species).
2) Видаляє службову колонку Id.
3) Перетворює текстові мітки класів (Iris-setosa/versicolor/virginica) у числа 0/1/2.
4) Ділить дані на train/val/test у пропорції 60/20/20 зі стратифікацією (важливо для
   збалансованості класів в кожному спліті).
5) Будує два класифікаційні пайплайни (StandardScaler + LogisticRegression):
   - L2-регуляризація (penalty='l2', solver='lbfgs') — стандартний і дуже стабільний варіант;
   - L1-регуляризація (penalty='l1', solver='liblinear') — виконує відбір ознак (деякі ваги = 0).
6) Для кожної моделі:
   - Друкує classification_report (precision/recall/F1/support) на train/val/test;
   - Друкує короткий "overfit report" на основі розриву між F1(train) і F1(val);
   - Будує Confusion Matrix на тесті (компактний огляд помилок);
   - Будує Learning Curve (F1_macro проти розміру тренувальної вибірки) — індикатор
     overfitting/underfitting;
   - Будує Validation Curve (F1_macro проти гіперпараметра C) — показує, де
     баланс регуляризації найкращий.

Ключові поняття:
- Logistic Regression — лінійний класифікатор, що моделює ймовірності класів через логіти.
- Регуляризація:
  * L2 (ридж) — штрафує великі ваги (квадрати коефіцієнтів), "згладжує" модель;
  * L1 (лассо) — штрафує абсолютні значення ваг, може занулювати деякі коєф., виконуючи відбір фіч.
- Параметр C — "зворотна сила регуляризації":
  * Малий C => сильна регуляризація (менші ваги, простіша модель, менший ризик overfit, але можливий underfit);
  * Великий C => слабка регуляризація (більші ваги, гнучкіша модель, вищий ризик overfit).

Стабільність кривих:
- Для learning_curve використовуємо StratifiedKFold і "абсолютні" train_sizes (60, 80, 100, 120),
  щоб у кожному фолді та підвибірці були всі три класи. Це прибирає типову помилку:
  "Only one class in the data" на малих підвибірках.
